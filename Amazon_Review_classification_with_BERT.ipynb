{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.9"
    },
    "colab": {
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jvrcFX2XNpxR",
        "outputId": "c8a397a3-03e2-4dca-ba6e-b3b28fc9530b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wOtG4cf0qVAZ"
      },
      "source": [
        "#all imports\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "from tensorflow.keras.models import Model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OcmiHdAJqVAi",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "dc711ee4-1d9f-4b81-a41a-6e9cbdd49c91"
      },
      "source": [
        "tf.test.gpu_device_name()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/device:GPU:0'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 177
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZTWRqbrBqVAu"
      },
      "source": [
        "<pre><font size=6>Part-1: Preprocessing</font></pre>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B3csZKDrqVAv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "09e60373-7a6a-40f3-9853-1942d8bc0fce"
      },
      "source": [
        "#Read the dataset - Amazon fine food reviews\n",
        "reviews = pd.read_csv(\"/content/drive/MyDrive/Reviews.csv\")\n",
        "#check the info of the dataset\n",
        "reviews.info()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 568454 entries, 0 to 568453\n",
            "Data columns (total 10 columns):\n",
            " #   Column                  Non-Null Count   Dtype \n",
            "---  ------                  --------------   ----- \n",
            " 0   Id                      568454 non-null  int64 \n",
            " 1   ProductId               568454 non-null  object\n",
            " 2   UserId                  568454 non-null  object\n",
            " 3   ProfileName             568438 non-null  object\n",
            " 4   HelpfulnessNumerator    568454 non-null  int64 \n",
            " 5   HelpfulnessDenominator  568454 non-null  int64 \n",
            " 6   Score                   568454 non-null  int64 \n",
            " 7   Time                    568454 non-null  int64 \n",
            " 8   Summary                 568427 non-null  object\n",
            " 9   Text                    568454 non-null  object\n",
            "dtypes: int64(5), object(5)\n",
            "memory usage: 43.4+ MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xokNn7qZqVAz"
      },
      "source": [
        "#get only 2 columns - Text, Score\n",
        "#drop the NAN values\n",
        "reviews = reviews[['Text','Score']]\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5GZt7pVkqVA4"
      },
      "source": [
        "#if score> 3, set score = 1\n",
        "#if score<=2, set score = 0\n",
        "#if score == 3, remove the rows. \n",
        "import math\n",
        "def score_preprocessor(i):\n",
        "  if i > 3 :\n",
        "    return 1\n",
        "  elif i <= 2 :\n",
        "    return 0\n",
        "  elif i == 3:\n",
        "    return math.nan\n",
        "reviews['Score'] = reviews['Score'].map(score_preprocessor)\n",
        "reviews = reviews.dropna()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "reviews['Score']"
      ],
      "metadata": {
        "id": "50AREHr6XnH-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7d848343-1298-4681-e934-501c4e192cf0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0         1.0\n",
              "1         0.0\n",
              "2         1.0\n",
              "3         0.0\n",
              "4         1.0\n",
              "         ... \n",
              "568449    1.0\n",
              "568450    0.0\n",
              "568451    1.0\n",
              "568452    1.0\n",
              "568453    1.0\n",
              "Name: Score, Length: 525814, dtype: float64"
            ]
          },
          "metadata": {},
          "execution_count": 182
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xYZ-UB9UqVA-"
      },
      "source": [
        "def get_wordlen(x):\n",
        "    return len(x.split())\n",
        "reviews['len'] = reviews.Text.apply(get_wordlen)\n",
        "reviews = reviews[reviews.len<50]\n",
        "reviews = reviews.sample(n=100000, random_state=30)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import re"
      ],
      "metadata": {
        "id": "K7Y5IcR4ZxFl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CvldQriGqVBB"
      },
      "source": [
        "#remove HTML from the Text column and save in the Text column only\n",
        "reviews['Text'] = reviews['Text'].map(lambda x: re.sub(r'<.*?>', '', x))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AhfN1s2mqVBD",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "c02f7033-1808-4be3-8fd8-d22ada95df32"
      },
      "source": [
        "#print head 5\n",
        "reviews.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                     Text  Score  len\n",
              "64117   The tea was of great quality and it tasted lik...    1.0   30\n",
              "418112  My cat loves this.  The pellets are nice and s...    1.0   31\n",
              "357829  Great product. Does not completely get rid of ...    1.0   41\n",
              "175872  This gum is my favorite!  I would advise every...    1.0   27\n",
              "178716  I also found out about this product because of...    1.0   22"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-25e80491-ec8e-4d02-bf7f-5cbf7050df86\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Text</th>\n",
              "      <th>Score</th>\n",
              "      <th>len</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>64117</th>\n",
              "      <td>The tea was of great quality and it tasted lik...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>30</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>418112</th>\n",
              "      <td>My cat loves this.  The pellets are nice and s...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>31</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>357829</th>\n",
              "      <td>Great product. Does not completely get rid of ...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>41</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>175872</th>\n",
              "      <td>This gum is my favorite!  I would advise every...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>27</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>178716</th>\n",
              "      <td>I also found out about this product because of...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>22</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-25e80491-ec8e-4d02-bf7f-5cbf7050df86')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-25e80491-ec8e-4d02-bf7f-5cbf7050df86 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-25e80491-ec8e-4d02-bf7f-5cbf7050df86');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 187
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NsYDd3okqVBF"
      },
      "source": [
        "#split the data into train and test data(20%) with Stratify sampling, random state 33, \n",
        "from sklearn.model_selection import train_test_split\n",
        "y = reviews['Score']\n",
        "X = reviews.drop(['Score'], axis=1)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y,test_size=0.3, random_state=33)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Q6OAcrOqVBI",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 395
        },
        "outputId": "1a6fdd45-00d6-4767-e89e-d51e86ed8c30"
      },
      "source": [
        "#plot bar graphs of y_train and y_test\n",
        "import matplotlib.pyplot as plt\n",
        "plt.style.use('seaborn-darkgrid')\n",
        "#plot bar graphs of y_train and y_test\n",
        "fig, ax = plt.subplots()\n",
        "width = 0.35\n",
        "indices = np.arange(2)\n",
        "counts = y_train.value_counts(normalize=True)\n",
        "print(counts)\n",
        "bar1 = ax.bar(indices, counts, width)\n",
        "counts = y_test.value_counts(normalize=True)\n",
        "print(counts)\n",
        "bar2 = ax.bar(indices + width, counts, width)\n",
        "ax.set_ylabel('counts')\n",
        "ax.set_xlabel('score')\n",
        "ax.set_title('count of scores')\n",
        "ax.set_xticks(indices + width/2)\n",
        "ax.set_xticklabels(['1', '2'])\n",
        "ax.legend((bar1[0], bar2[0]), ('train', 'test'))\n",
        "fig.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.0    0.870043\n",
            "0.0    0.129957\n",
            "Name: Score, dtype: float64\n",
            "1.0    0.870033\n",
            "0.0    0.129967\n",
            "Name: Score, dtype: float64\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Up-z5boWqVBK"
      },
      "source": [
        "#saving to disk. if we need, we can load preprocessed data directly. \n",
        "reviews.to_csv('preprocessed.csv', index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bBtqNGN9qVBM"
      },
      "source": [
        "<pre><font size=6>Part-2: Creating BERT Model</font> \n",
        "\n",
        "If you want to know more about BERT, You can watch live sessions on Transformers and BERt. \n",
        "we will strongly recommend you to read <a href=\"https://jalammar.github.io/illustrated-transformer/\">Transformers</a>, <a href=\"https://arxiv.org/abs/1810.04805\">BERT Paper</a> and, <a href=\"https://jalammar.github.io/a-visual-guide-to-using-bert-for-the-first-time/\">This blog</a>.\n",
        "\n",
        "\n",
        "For this assignment, we are using <a href=\"https://tfhub.dev/tensorflow/bert_en_uncased_L-12_H-768_A-12/1\">BERT uncased Base model</a>. \n",
        "It uses L=12 hidden layers (i.e., Transformer blocks), a hidden size of H=768, and A=12 attention heads. </pre>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i8xd2HejqVBN"
      },
      "source": [
        "## Loading the Pretrained Model from tensorflow HUB\n",
        "tf.keras.backend.clear_session()\n",
        "\n",
        "# maximum length of a seq in the data we have, for now i am making it as 55. You can change this\n",
        "max_seq_length = 55\n",
        "\n",
        "#BERT takes 3 inputs\n",
        "\n",
        "#this is input words. Sequence of words represented as integers\n",
        "input_word_ids = tf.keras.layers.Input(shape=(max_seq_length,), dtype=tf.int32, name=\"input_word_ids\")\n",
        "\n",
        "#mask vector if you are padding anything\n",
        "input_mask = tf.keras.layers.Input(shape=(max_seq_length,), dtype=tf.int32, name=\"input_mask\")\n",
        "\n",
        "#segment vectors. If you are giving only one sentence for the classification, total seg vector is 0. \n",
        "#If you are giving two sentenced with [sep] token separated, first seq segment vectors are zeros and \n",
        "#second seq segment vector are 1's\n",
        "segment_ids = tf.keras.layers.Input(shape=(max_seq_length,), dtype=tf.int32, name=\"segment_ids\")\n",
        "\n",
        "#bert layer \n",
        "bert_layer = hub.KerasLayer(\"https://tfhub.dev/tensorflow/bert_en_uncased_L-12_H-768_A-12/1\", trainable=False)\n",
        "pooled_output, sequence_output = bert_layer([input_word_ids, input_mask, segment_ids])\n",
        "\n",
        "#Bert model\n",
        "#We are using only pooled output not sequence out. \n",
        "#If you want to know about those, please read https://www.kaggle.com/questions-and-answers/86510\n",
        "bert_model = Model(inputs=[[input_word_ids], [input_mask], [segment_ids]], outputs=pooled_output)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lQJsjg6fqVBQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "53d5fec1-91bd-4bf4-8384-730a96c8fa02"
      },
      "source": [
        "bert_model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_word_ids (InputLayer)    [(None, 55)]         0           []                               \n",
            "                                                                                                  \n",
            " input_mask (InputLayer)        [(None, 55)]         0           []                               \n",
            "                                                                                                  \n",
            " segment_ids (InputLayer)       [(None, 55)]         0           []                               \n",
            "                                                                                                  \n",
            " keras_layer (KerasLayer)       [(None, 768),        109482241   ['input_word_ids[0][0]',         \n",
            "                                 (None, 55, 768)]                 'input_mask[0][0]',             \n",
            "                                                                  'segment_ids[0][0]']            \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 109,482,241\n",
            "Trainable params: 0\n",
            "Non-trainable params: 109,482,241\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w3z0OMA5qVBS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "229e3716-afd7-4a07-d2f9-0aa201ab230e"
      },
      "source": [
        "bert_model.output"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<KerasTensor: shape=(None, 768) dtype=float32 (created by layer 'keras_layer')>"
            ]
          },
          "metadata": {},
          "execution_count": 193
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ewv4hFCsqVBU"
      },
      "source": [
        "<pre><font size=6>Part-3: Tokenization</font></pre>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tX3VEFjiqVBU"
      },
      "source": [
        "#getting Vocab file\n",
        "vocab_file = bert_layer.resolved_object.vocab_file.asset_path.numpy()\n",
        "do_lower_case = bert_layer.resolved_object.do_lower_case.numpy()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y_iPwa99qVBW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cbac933f-1beb-44cd-abfe-c1cfafe7fc0a"
      },
      "source": [
        "!pip install sentencepiece\n",
        "import tokenization #- #We have given tokenization.py file"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.7/dist-packages (0.1.96)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "guJMLJ8bqVBY"
      },
      "source": [
        "# Create tokenizer \" Instantiate FullTokenizer\" \n",
        "# name must be \"tokenizer\"\n",
        "# the FullTokenizer takes two parameters 1. vocab_file and 2. do_lower_case \n",
        "# we have created these in the above cell ex: FullTokenizer(vocab_file, do_lower_case )\n",
        "# please check the \"tokenization.py\" file the complete implementation\n",
        "tokenizer = tokenization.FullTokenizer(vocab_file, do_lower_case)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qlGFtp2xxzt6"
      },
      "source": [
        "# if you are getting error for sentencepiece module you can install it using below command while running this cell for the first time\n",
        "\n",
        "tokenizer=tokenization.FullTokenizer(vocab_file,do_lower_case )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9crhPylQqVBg"
      },
      "source": [
        "\n",
        "# Create train and test tokens (X_train_tokens, X_test_tokens) from (X_train, X_test) using Tokenizer and \n",
        "X_train_tokens = X_train['Text'].map(tokenizer.tokenize)\n",
        "X_test_tokens = X_test['Text'].map(tokenizer.tokenize)\n",
        "# add '[CLS]' at start of the Tokens and '[SEP]' at the end of the tokens. \n",
        "\n",
        "# maximum number of tokens is 55(We already given this to BERT layer above) so shape is (None, 55)\n",
        "X_train_tokens = tf.keras.preprocessing.sequence.pad_sequences(X_train_tokens, maxlen=max_seq_length-2,value='[PAD]', dtype=object)\n",
        "X_test_tokens = tf.keras.preprocessing.sequence.pad_sequences(X_test_tokens, maxlen=max_seq_length-2,value='[PAD]', dtype=object)\n",
        "# if it is less than 55, add '[PAD]' token else truncate the tokens length.(similar to padding)\n",
        "def tokenize_sequence(text):\n",
        "  seq = []\n",
        "  for row in text:\n",
        "    seq.append(['[CLS]', *row, '[SEP]'])\n",
        "  return np.array(seq)\n",
        "X_train_tokens = tokenize_sequence(X_train_tokens)\n",
        "X_test_tokens = tokenize_sequence(X_test_tokens)\n",
        "# Based on padding, create the mask for Train and Test ( 1 for real token, 0 for '[PAD]'), \n",
        "# it will also same shape as input tokens (None, 55) save those in X_train_mask, X_test_mask\n",
        "X_train_mask = (X_train_tokens != '[PAD]')\n",
        "X_test_mask = (X_test_tokens != '[PAD]')\n",
        "# Create a segment input for train and test. We are using only one sentence so all zeros. This shape will also (None, 55)\n",
        "X_train_segment = np.zeros(X_train_tokens.shape)\n",
        "X_test_segment = np.zeros(X_test_tokens.shape)\n",
        "# type of all the above arrays should be numpy arrays\n",
        "\n",
        "# after execution of this cell, you have to get \n",
        "# X_train_tokens, X_train_mask, X_train_segment\n",
        "# X_test_tokens, X_test_mask, X_test_segment\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def convert_tokens_to_ids(text, tokenizer):\n",
        "  ids = []\n",
        "  for row in text:\n",
        "    ids.append(tokenizer.convert_tokens_to_ids(row))\n",
        "  return np.array(ids)\n",
        "\n",
        "\n",
        "X_train_tokens = convert_tokens_to_ids(X_train_tokens, tokenizer)\n",
        "X_test_tokens = convert_tokens_to_ids(X_test_tokens, tokenizer)"
      ],
      "metadata": {
        "id": "OcmNocJI3AWW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dxhggBxwqVBj"
      },
      "source": [
        "import pickle"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xF0idMRDqVBm"
      },
      "source": [
        "##save all your results to disk so that, no need to run all again. \n",
        "pickle.dump((X_train, X_train_tokens, X_train_mask, X_train_segment, y_train),open('train_data.pkl','wb'))\n",
        "pickle.dump((X_test, X_test_tokens, X_test_mask, X_test_segment, y_test),open('test_data.pkl','wb'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Leu1URGzqVBo"
      },
      "source": [
        "#you can load from disk\n",
        "#X_train, X_train_tokens, X_train_mask, X_train_segment, y_train = pickle.load(open(\"train_data.pkl\", 'rb')) \n",
        "#X_test, X_test_tokens, X_test_mask, X_test_segment, y_test = pickle.load(open(\"test_data.pkl\", 'rb')) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SEj-Eua5qVBx"
      },
      "source": [
        "<pre><font size=6>Part-4: Getting Embeddings from BERT Model</font>\n",
        "We already created the BERT model in the part-2 and input data in the part-3. \n",
        "We will utlize those two and will get the embeddings for each sentence in the \n",
        "Train and test data.</pre>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QwOVgQFDqVBy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0a7a34e6-0c81-40a4-a95d-9e1518080e2f"
      },
      "source": [
        "bert_model.input"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[<KerasTensor: shape=(None, 55) dtype=int32 (created by layer 'input_word_ids')>],\n",
              " [<KerasTensor: shape=(None, 55) dtype=int32 (created by layer 'input_mask')>],\n",
              " [<KerasTensor: shape=(None, 55) dtype=int32 (created by layer 'segment_ids')>]]"
            ]
          },
          "metadata": {},
          "execution_count": 207
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZcpkQq1OqVB0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d41fd7ee-9f9a-422c-9799-08197705a818"
      },
      "source": [
        "bert_model.output"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<KerasTensor: shape=(None, 768) dtype=float32 (created by layer 'keras_layer')>"
            ]
          },
          "metadata": {},
          "execution_count": 208
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IxdIlOIBlm7j"
      },
      "source": [
        "# get the train output, BERT model will give one output so save in\n",
        "# X_train_pooled_output\n",
        "#this cell will take some time to execute, make sure thay you have stable internet connection\n",
        "X_train_pooled_output=bert_model.predict([[X_train_tokens],[X_train_mask],[X_train_segment]])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yZT11BCol4gL"
      },
      "source": [
        "# get the test output, BERT model will give one output so save in\n",
        "# X_test_pooled_output\n",
        "X_test_pooled_output=bert_model.predict([[X_test_tokens],[X_test_mask],[X_test_segment]])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DL6JVojfqVB8"
      },
      "source": [
        "##save all your results to disk so that, no need to run all again. \n",
        "pickle.dump((X_train_pooled_output, X_test_pooled_output),open('final_output.pkl','wb'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oSQcBdROqVB9"
      },
      "source": [
        "X_train_pooled_output, X_test_pooled_output= pickle.load(open('final_output.pkl', 'rb'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oYwS1QbAqVCD"
      },
      "source": [
        "<pre><font size=6>Part-5: Training a NN with 768 features</font>\n",
        "\n",
        "Create a NN and train the NN. \n",
        "1.<b> You have to use AUC as metric. Do not use tf.keras.metrics.AUC</b> \n",
        "<b> You have to write custom code for AUC and print it at the end of each epoch</b> \n",
        "2. You can use any architecture you want. \n",
        "3. You have to use tensorboard to log all your metrics and Losses. You have to send those logs. \n",
        "4. Print the loss and metric at every epoch. \n",
        "5. You have to submit without overfitting and underfitting. \n",
        "</pre>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "X_train, X_train_tokens, X_train_mask, X_train_segment, y_train = pickle.load(open(\"/content/drive/MyDrive/train_data.pkl\", 'rb')) \n",
        "X_test, X_test_tokens, X_test_mask, X_test_segment, y_test = pickle.load(open(\"/content/drive/MyDrive/test_data.pkl\", 'rb')) \n",
        "X_train_pooled_output, X_test_pooled_output= pickle.load(open('/content/drive/MyDrive/final_output.pkl', 'rb'))"
      ],
      "metadata": {
        "id": "qFWM7M1mYDZI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import OneHotEncoder"
      ],
      "metadata": {
        "id": "l43x0mZ7FiYQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_train = OneHotEncoder().fit_transform(np.array(y_train).reshape(-1,1)).toarray()"
      ],
      "metadata": {
        "id": "gvoOP_REEZrN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_test = OneHotEncoder().fit_transform(np.array(y_test).reshape(-1,1)).toarray()"
      ],
      "metadata": {
        "id": "wEl84VOJFBzA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "od8PQlYRqVCE"
      },
      "source": [
        "##imports\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Input, Dense, Activation, Dropout, LSTM, BatchNormalization,Flatten\n",
        "from tensorflow.keras.models import Model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.callbacks import (Callback, EarlyStopping,TensorBoard, ReduceLROnPlateau)"
      ],
      "metadata": {
        "id": "d2yDmqOcfs7e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import roc_auc_score\n",
        "def auc_score(y_true, y_pred):\n",
        "    if len(np.unique(y_true[:,1])) == 1:\n",
        "        return 0.5\n",
        "    else:\n",
        "        return roc_auc_score(y_true, y_pred)\n",
        "def auc(y_true, y_pred):\n",
        "    return tf.py_function(auc_score, (y_true, y_pred), tf.double)"
      ],
      "metadata": {
        "id": "GsbZlee1WnBi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_layer=Input(shape=(X_train_pooled_output.shape[1],))\n",
        "dense_layer_1 = Dense(64, activation='relu')(input_layer)\n",
        "dense_layer_2 = Dense(32, activation='relu')(dense_layer_1)\n",
        "dense_layer_3 = Dense(16, activation='relu')(dense_layer_2)\n",
        "output_layer = Dense(2, activation='softmax')(dense_layer_3)\n",
        "\n",
        "model = tf.keras.Model(inputs=input_layer, outputs= output_layer)\n",
        "\n",
        "reduce_lr = ReduceLROnPlateau(patience=3)\n",
        "earlystop = tf.keras.callbacks.EarlyStopping(patience=10, verbose=1)\n",
        "tensor = tf.keras.callbacks.TensorBoard(log_dir='logs_bert', histogram_freq=0, write_graph=True,write_images=False, write_steps_per_second=False, update_freq='epoch')\n",
        "adam = tf.keras.optimizers.Adam(lr=1e-4)\n",
        "model.compile(loss='categorical_crossentropy', optimizer=adam,metrics=['accuracy',auc])\n",
        "print(model.summary())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d5ykMtvIqlrt",
        "outputId": "7d54273a-2373-4d5f-8c0e-c22a24c9c42a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(None, 768)]             0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 64)                49216     \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 32)                2080      \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 16)                528       \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 2)                 34        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 51,858\n",
            "Trainable params: 51,858\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class_weight = {0: 0.15602, 1: 0.84398}"
      ],
      "metadata": {
        "id": "7PPtES27Kmwx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(X_train_pooled_output, y_train, batch_size=256,epochs=100, validation_data=(X_test_pooled_output,y_test),class_weight = {0: 0.16, 1: 0.84} ,callbacks=[tensor])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JqmXb2slruG1",
        "outputId": "ba3bb281-61c5-44c8-ebd9-d84df523da54"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "274/274 [==============================] - 4s 14ms/step - loss: 0.0943 - accuracy: 0.8700 - auc: 0.7195 - val_loss: 0.4418 - val_accuracy: 0.8700 - val_auc: 0.8256\n",
            "Epoch 2/100\n",
            "274/274 [==============================] - 4s 13ms/step - loss: 0.0810 - accuracy: 0.8700 - auc: 0.8537 - val_loss: 0.3893 - val_accuracy: 0.8700 - val_auc: 0.8749\n",
            "Epoch 3/100\n",
            "274/274 [==============================] - 4s 13ms/step - loss: 0.0718 - accuracy: 0.8700 - auc: 0.8959 - val_loss: 0.3262 - val_accuracy: 0.8700 - val_auc: 0.9083\n",
            "Epoch 4/100\n",
            "274/274 [==============================] - 3s 11ms/step - loss: 0.0644 - accuracy: 0.8701 - auc: 0.9202 - val_loss: 0.3105 - val_accuracy: 0.8703 - val_auc: 0.9256\n",
            "Epoch 5/100\n",
            "274/274 [==============================] - 4s 13ms/step - loss: 0.0600 - accuracy: 0.8753 - auc: 0.9316 - val_loss: 0.3201 - val_accuracy: 0.8740 - val_auc: 0.9333\n",
            "Epoch 6/100\n",
            "274/274 [==============================] - 3s 11ms/step - loss: 0.0579 - accuracy: 0.8843 - auc: 0.9374 - val_loss: 0.2937 - val_accuracy: 0.8812 - val_auc: 0.9376\n",
            "Epoch 7/100\n",
            "274/274 [==============================] - 3s 11ms/step - loss: 0.0564 - accuracy: 0.8894 - auc: 0.9409 - val_loss: 0.3767 - val_accuracy: 0.8736 - val_auc: 0.9396\n",
            "Epoch 8/100\n",
            "274/274 [==============================] - 3s 13ms/step - loss: 0.0561 - accuracy: 0.8926 - auc: 0.9429 - val_loss: 0.2581 - val_accuracy: 0.8957 - val_auc: 0.9419\n",
            "Epoch 9/100\n",
            "274/274 [==============================] - 3s 11ms/step - loss: 0.0543 - accuracy: 0.8959 - auc: 0.9451 - val_loss: 0.2460 - val_accuracy: 0.9001 - val_auc: 0.9433\n",
            "Epoch 10/100\n",
            "274/274 [==============================] - 3s 13ms/step - loss: 0.0538 - accuracy: 0.8966 - auc: 0.9463 - val_loss: 0.2196 - val_accuracy: 0.9118 - val_auc: 0.9444\n",
            "Epoch 11/100\n",
            "274/274 [==============================] - 4s 13ms/step - loss: 0.0533 - accuracy: 0.8985 - auc: 0.9476 - val_loss: 0.2459 - val_accuracy: 0.9018 - val_auc: 0.9452\n",
            "Epoch 12/100\n",
            "274/274 [==============================] - 4s 13ms/step - loss: 0.0534 - accuracy: 0.9002 - auc: 0.9486 - val_loss: 0.3238 - val_accuracy: 0.8829 - val_auc: 0.9461\n",
            "Epoch 13/100\n",
            "274/274 [==============================] - 3s 11ms/step - loss: 0.0528 - accuracy: 0.9007 - auc: 0.9496 - val_loss: 0.2400 - val_accuracy: 0.9056 - val_auc: 0.9474\n",
            "Epoch 14/100\n",
            "274/274 [==============================] - 4s 13ms/step - loss: 0.0520 - accuracy: 0.9022 - auc: 0.9504 - val_loss: 0.2198 - val_accuracy: 0.9137 - val_auc: 0.9476\n",
            "Epoch 15/100\n",
            "274/274 [==============================] - 3s 11ms/step - loss: 0.0516 - accuracy: 0.9037 - auc: 0.9511 - val_loss: 0.2581 - val_accuracy: 0.9004 - val_auc: 0.9490\n",
            "Epoch 16/100\n",
            "274/274 [==============================] - 3s 13ms/step - loss: 0.0515 - accuracy: 0.9037 - auc: 0.9515 - val_loss: 0.2471 - val_accuracy: 0.9023 - val_auc: 0.9494\n",
            "Epoch 17/100\n",
            "274/274 [==============================] - 3s 13ms/step - loss: 0.0512 - accuracy: 0.9050 - auc: 0.9522 - val_loss: 0.2311 - val_accuracy: 0.9072 - val_auc: 0.9496\n",
            "Epoch 18/100\n",
            "274/274 [==============================] - 4s 13ms/step - loss: 0.0510 - accuracy: 0.9051 - auc: 0.9524 - val_loss: 0.2447 - val_accuracy: 0.9012 - val_auc: 0.9504\n",
            "Epoch 19/100\n",
            "274/274 [==============================] - 3s 11ms/step - loss: 0.0508 - accuracy: 0.9052 - auc: 0.9533 - val_loss: 0.2235 - val_accuracy: 0.9107 - val_auc: 0.9507\n",
            "Epoch 20/100\n",
            "274/274 [==============================] - 3s 11ms/step - loss: 0.0507 - accuracy: 0.9054 - auc: 0.9538 - val_loss: 0.2814 - val_accuracy: 0.8954 - val_auc: 0.9511\n",
            "Epoch 21/100\n",
            "274/274 [==============================] - 4s 13ms/step - loss: 0.0504 - accuracy: 0.9065 - auc: 0.9544 - val_loss: 0.2319 - val_accuracy: 0.9109 - val_auc: 0.9514\n",
            "Epoch 22/100\n",
            "274/274 [==============================] - 4s 13ms/step - loss: 0.0501 - accuracy: 0.9074 - auc: 0.9547 - val_loss: 0.2526 - val_accuracy: 0.9006 - val_auc: 0.9517\n",
            "Epoch 23/100\n",
            "274/274 [==============================] - 4s 13ms/step - loss: 0.0502 - accuracy: 0.9069 - auc: 0.9548 - val_loss: 0.2302 - val_accuracy: 0.9099 - val_auc: 0.9522\n",
            "Epoch 24/100\n",
            "274/274 [==============================] - 3s 11ms/step - loss: 0.0498 - accuracy: 0.9084 - auc: 0.9552 - val_loss: 0.2706 - val_accuracy: 0.8953 - val_auc: 0.9525\n",
            "Epoch 25/100\n",
            "274/274 [==============================] - 3s 11ms/step - loss: 0.0494 - accuracy: 0.9087 - auc: 0.9556 - val_loss: 0.2183 - val_accuracy: 0.9138 - val_auc: 0.9519\n",
            "Epoch 26/100\n",
            "274/274 [==============================] - 4s 13ms/step - loss: 0.0493 - accuracy: 0.9092 - auc: 0.9556 - val_loss: 0.2051 - val_accuracy: 0.9196 - val_auc: 0.9521\n",
            "Epoch 27/100\n",
            "274/274 [==============================] - 4s 13ms/step - loss: 0.0495 - accuracy: 0.9079 - auc: 0.9562 - val_loss: 0.2882 - val_accuracy: 0.8941 - val_auc: 0.9529\n",
            "Epoch 28/100\n",
            "274/274 [==============================] - 3s 11ms/step - loss: 0.0491 - accuracy: 0.9096 - auc: 0.9569 - val_loss: 0.2605 - val_accuracy: 0.8995 - val_auc: 0.9526\n",
            "Epoch 29/100\n",
            "274/274 [==============================] - 3s 13ms/step - loss: 0.0490 - accuracy: 0.9104 - auc: 0.9567 - val_loss: 0.2301 - val_accuracy: 0.9115 - val_auc: 0.9537\n",
            "Epoch 30/100\n",
            "274/274 [==============================] - 4s 13ms/step - loss: 0.0486 - accuracy: 0.9102 - auc: 0.9572 - val_loss: 0.2130 - val_accuracy: 0.9170 - val_auc: 0.9538\n",
            "Epoch 31/100\n",
            "274/274 [==============================] - 3s 11ms/step - loss: 0.0486 - accuracy: 0.9109 - auc: 0.9574 - val_loss: 0.2221 - val_accuracy: 0.9136 - val_auc: 0.9541\n",
            "Epoch 32/100\n",
            "274/274 [==============================] - 3s 11ms/step - loss: 0.0488 - accuracy: 0.9107 - auc: 0.9575 - val_loss: 0.2242 - val_accuracy: 0.9099 - val_auc: 0.9539\n",
            "Epoch 33/100\n",
            "274/274 [==============================] - 4s 13ms/step - loss: 0.0486 - accuracy: 0.9105 - auc: 0.9577 - val_loss: 0.1947 - val_accuracy: 0.9221 - val_auc: 0.9543\n",
            "Epoch 34/100\n",
            "274/274 [==============================] - 3s 11ms/step - loss: 0.0487 - accuracy: 0.9111 - auc: 0.9578 - val_loss: 0.2562 - val_accuracy: 0.9002 - val_auc: 0.9548\n",
            "Epoch 35/100\n",
            "274/274 [==============================] - 4s 13ms/step - loss: 0.0480 - accuracy: 0.9114 - auc: 0.9584 - val_loss: 0.2463 - val_accuracy: 0.9062 - val_auc: 0.9549\n",
            "Epoch 36/100\n",
            "274/274 [==============================] - 4s 13ms/step - loss: 0.0484 - accuracy: 0.9116 - auc: 0.9584 - val_loss: 0.2574 - val_accuracy: 0.9040 - val_auc: 0.9549\n",
            "Epoch 37/100\n",
            "274/274 [==============================] - 4s 13ms/step - loss: 0.0480 - accuracy: 0.9118 - auc: 0.9586 - val_loss: 0.2007 - val_accuracy: 0.9208 - val_auc: 0.9543\n",
            "Epoch 38/100\n",
            "274/274 [==============================] - 3s 11ms/step - loss: 0.0475 - accuracy: 0.9133 - auc: 0.9590 - val_loss: 0.2032 - val_accuracy: 0.9202 - val_auc: 0.9551\n",
            "Epoch 39/100\n",
            "274/274 [==============================] - 3s 11ms/step - loss: 0.0478 - accuracy: 0.9126 - auc: 0.9595 - val_loss: 0.2714 - val_accuracy: 0.8964 - val_auc: 0.9553\n",
            "Epoch 40/100\n",
            "274/274 [==============================] - 3s 13ms/step - loss: 0.0475 - accuracy: 0.9128 - auc: 0.9589 - val_loss: 0.2148 - val_accuracy: 0.9164 - val_auc: 0.9556\n",
            "Epoch 41/100\n",
            "274/274 [==============================] - 3s 12ms/step - loss: 0.0478 - accuracy: 0.9131 - auc: 0.9595 - val_loss: 0.2006 - val_accuracy: 0.9214 - val_auc: 0.9553\n",
            "Epoch 42/100\n",
            "274/274 [==============================] - 3s 11ms/step - loss: 0.0472 - accuracy: 0.9137 - auc: 0.9600 - val_loss: 0.2307 - val_accuracy: 0.9110 - val_auc: 0.9556\n",
            "Epoch 43/100\n",
            "274/274 [==============================] - 4s 13ms/step - loss: 0.0472 - accuracy: 0.9141 - auc: 0.9601 - val_loss: 0.2167 - val_accuracy: 0.9148 - val_auc: 0.9561\n",
            "Epoch 44/100\n",
            "274/274 [==============================] - 4s 13ms/step - loss: 0.0474 - accuracy: 0.9136 - auc: 0.9603 - val_loss: 0.2560 - val_accuracy: 0.9024 - val_auc: 0.9562\n",
            "Epoch 45/100\n",
            "274/274 [==============================] - 4s 13ms/step - loss: 0.0473 - accuracy: 0.9142 - auc: 0.9606 - val_loss: 0.2366 - val_accuracy: 0.9094 - val_auc: 0.9562\n",
            "Epoch 46/100\n",
            "274/274 [==============================] - 3s 11ms/step - loss: 0.0473 - accuracy: 0.9137 - auc: 0.9606 - val_loss: 0.1853 - val_accuracy: 0.9268 - val_auc: 0.9561\n",
            "Epoch 47/100\n",
            "274/274 [==============================] - 4s 13ms/step - loss: 0.0468 - accuracy: 0.9144 - auc: 0.9607 - val_loss: 0.2275 - val_accuracy: 0.9121 - val_auc: 0.9565\n",
            "Epoch 48/100\n",
            "274/274 [==============================] - 3s 11ms/step - loss: 0.0467 - accuracy: 0.9148 - auc: 0.9609 - val_loss: 0.2150 - val_accuracy: 0.9182 - val_auc: 0.9567\n",
            "Epoch 49/100\n",
            "274/274 [==============================] - 3s 11ms/step - loss: 0.0474 - accuracy: 0.9139 - auc: 0.9612 - val_loss: 0.2462 - val_accuracy: 0.9036 - val_auc: 0.9566\n",
            "Epoch 50/100\n",
            "274/274 [==============================] - 3s 11ms/step - loss: 0.0464 - accuracy: 0.9155 - auc: 0.9614 - val_loss: 0.2174 - val_accuracy: 0.9161 - val_auc: 0.9568\n",
            "Epoch 51/100\n",
            "274/274 [==============================] - 4s 13ms/step - loss: 0.0466 - accuracy: 0.9155 - auc: 0.9609 - val_loss: 0.2113 - val_accuracy: 0.9193 - val_auc: 0.9565\n",
            "Epoch 52/100\n",
            "274/274 [==============================] - 4s 13ms/step - loss: 0.0465 - accuracy: 0.9155 - auc: 0.9619 - val_loss: 0.2336 - val_accuracy: 0.9084 - val_auc: 0.9572\n",
            "Epoch 53/100\n",
            "274/274 [==============================] - 4s 13ms/step - loss: 0.0463 - accuracy: 0.9152 - auc: 0.9617 - val_loss: 0.2613 - val_accuracy: 0.9046 - val_auc: 0.9568\n",
            "Epoch 54/100\n",
            "274/274 [==============================] - 3s 11ms/step - loss: 0.0468 - accuracy: 0.9147 - auc: 0.9620 - val_loss: 0.2600 - val_accuracy: 0.9058 - val_auc: 0.9576\n",
            "Epoch 55/100\n",
            "274/274 [==============================] - 3s 11ms/step - loss: 0.0465 - accuracy: 0.9155 - auc: 0.9621 - val_loss: 0.2419 - val_accuracy: 0.9087 - val_auc: 0.9575\n",
            "Epoch 56/100\n",
            "274/274 [==============================] - 3s 11ms/step - loss: 0.0457 - accuracy: 0.9171 - auc: 0.9622 - val_loss: 0.1996 - val_accuracy: 0.9222 - val_auc: 0.9572\n",
            "Epoch 57/100\n",
            "274/274 [==============================] - 4s 13ms/step - loss: 0.0456 - accuracy: 0.9176 - auc: 0.9625 - val_loss: 0.1933 - val_accuracy: 0.9244 - val_auc: 0.9577\n",
            "Epoch 58/100\n",
            "274/274 [==============================] - 3s 11ms/step - loss: 0.0464 - accuracy: 0.9159 - auc: 0.9625 - val_loss: 0.2103 - val_accuracy: 0.9205 - val_auc: 0.9576\n",
            "Epoch 59/100\n",
            "274/274 [==============================] - 3s 11ms/step - loss: 0.0463 - accuracy: 0.9159 - auc: 0.9623 - val_loss: 0.2811 - val_accuracy: 0.8981 - val_auc: 0.9570\n",
            "Epoch 60/100\n",
            "274/274 [==============================] - 3s 11ms/step - loss: 0.0461 - accuracy: 0.9169 - auc: 0.9629 - val_loss: 0.3060 - val_accuracy: 0.8912 - val_auc: 0.9577\n",
            "Epoch 61/100\n",
            "274/274 [==============================] - 3s 11ms/step - loss: 0.0458 - accuracy: 0.9169 - auc: 0.9636 - val_loss: 0.2396 - val_accuracy: 0.9105 - val_auc: 0.9582\n",
            "Epoch 62/100\n",
            "274/274 [==============================] - 3s 11ms/step - loss: 0.0459 - accuracy: 0.9163 - auc: 0.9635 - val_loss: 0.2772 - val_accuracy: 0.9019 - val_auc: 0.9583\n",
            "Epoch 63/100\n",
            "274/274 [==============================] - 4s 13ms/step - loss: 0.0458 - accuracy: 0.9166 - auc: 0.9635 - val_loss: 0.2192 - val_accuracy: 0.9128 - val_auc: 0.9577\n",
            "Epoch 64/100\n",
            "274/274 [==============================] - 4s 13ms/step - loss: 0.0455 - accuracy: 0.9168 - auc: 0.9635 - val_loss: 0.1910 - val_accuracy: 0.9239 - val_auc: 0.9585\n",
            "Epoch 65/100\n",
            "274/274 [==============================] - 5s 19ms/step - loss: 0.0456 - accuracy: 0.9173 - auc: 0.9637 - val_loss: 0.2309 - val_accuracy: 0.9150 - val_auc: 0.9586\n",
            "Epoch 66/100\n",
            "274/274 [==============================] - 6s 20ms/step - loss: 0.0456 - accuracy: 0.9177 - auc: 0.9632 - val_loss: 0.2101 - val_accuracy: 0.9201 - val_auc: 0.9584\n",
            "Epoch 67/100\n",
            "274/274 [==============================] - 6s 20ms/step - loss: 0.0454 - accuracy: 0.9179 - auc: 0.9637 - val_loss: 0.2369 - val_accuracy: 0.9108 - val_auc: 0.9585\n",
            "Epoch 68/100\n",
            "274/274 [==============================] - 6s 21ms/step - loss: 0.0459 - accuracy: 0.9171 - auc: 0.9638 - val_loss: 0.1945 - val_accuracy: 0.9242 - val_auc: 0.9586\n",
            "Epoch 69/100\n",
            "274/274 [==============================] - 5s 20ms/step - loss: 0.0448 - accuracy: 0.9196 - auc: 0.9640 - val_loss: 0.2654 - val_accuracy: 0.9030 - val_auc: 0.9591\n",
            "Epoch 70/100\n",
            "274/274 [==============================] - 4s 14ms/step - loss: 0.0457 - accuracy: 0.9170 - auc: 0.9641 - val_loss: 0.2133 - val_accuracy: 0.9167 - val_auc: 0.9590\n",
            "Epoch 71/100\n",
            "274/274 [==============================] - 3s 11ms/step - loss: 0.0452 - accuracy: 0.9185 - auc: 0.9644 - val_loss: 0.2533 - val_accuracy: 0.9085 - val_auc: 0.9592\n",
            "Epoch 72/100\n",
            "274/274 [==============================] - 3s 11ms/step - loss: 0.0449 - accuracy: 0.9194 - auc: 0.9646 - val_loss: 0.2401 - val_accuracy: 0.9123 - val_auc: 0.9592\n",
            "Epoch 73/100\n",
            "274/274 [==============================] - 3s 11ms/step - loss: 0.0448 - accuracy: 0.9191 - auc: 0.9645 - val_loss: 0.2416 - val_accuracy: 0.9096 - val_auc: 0.9594\n",
            "Epoch 74/100\n",
            "274/274 [==============================] - 3s 11ms/step - loss: 0.0449 - accuracy: 0.9186 - auc: 0.9649 - val_loss: 0.2030 - val_accuracy: 0.9204 - val_auc: 0.9589\n",
            "Epoch 75/100\n",
            "274/274 [==============================] - 4s 13ms/step - loss: 0.0450 - accuracy: 0.9182 - auc: 0.9647 - val_loss: 0.2683 - val_accuracy: 0.9055 - val_auc: 0.9595\n",
            "Epoch 76/100\n",
            "274/274 [==============================] - 3s 11ms/step - loss: 0.0451 - accuracy: 0.9183 - auc: 0.9648 - val_loss: 0.2036 - val_accuracy: 0.9185 - val_auc: 0.9593\n",
            "Epoch 77/100\n",
            "274/274 [==============================] - 3s 11ms/step - loss: 0.0445 - accuracy: 0.9198 - auc: 0.9651 - val_loss: 0.2618 - val_accuracy: 0.9022 - val_auc: 0.9596\n",
            "Epoch 78/100\n",
            "274/274 [==============================] - 4s 13ms/step - loss: 0.0448 - accuracy: 0.9185 - auc: 0.9654 - val_loss: 0.1906 - val_accuracy: 0.9264 - val_auc: 0.9594\n",
            "Epoch 79/100\n",
            "274/274 [==============================] - 4s 13ms/step - loss: 0.0449 - accuracy: 0.9195 - auc: 0.9656 - val_loss: 0.2636 - val_accuracy: 0.9046 - val_auc: 0.9597\n",
            "Epoch 80/100\n",
            "274/274 [==============================] - 4s 13ms/step - loss: 0.0446 - accuracy: 0.9190 - auc: 0.9656 - val_loss: 0.1988 - val_accuracy: 0.9223 - val_auc: 0.9598\n",
            "Epoch 81/100\n",
            "274/274 [==============================] - 4s 13ms/step - loss: 0.0441 - accuracy: 0.9202 - auc: 0.9657 - val_loss: 0.1666 - val_accuracy: 0.9348 - val_auc: 0.9594\n",
            "Epoch 82/100\n",
            "274/274 [==============================] - 4s 13ms/step - loss: 0.0452 - accuracy: 0.9188 - auc: 0.9656 - val_loss: 0.2371 - val_accuracy: 0.9102 - val_auc: 0.9600\n",
            "Epoch 83/100\n",
            "274/274 [==============================] - 3s 12ms/step - loss: 0.0451 - accuracy: 0.9180 - auc: 0.9659 - val_loss: 0.2264 - val_accuracy: 0.9145 - val_auc: 0.9602\n",
            "Epoch 84/100\n",
            "274/274 [==============================] - 3s 11ms/step - loss: 0.0445 - accuracy: 0.9202 - auc: 0.9658 - val_loss: 0.2414 - val_accuracy: 0.9136 - val_auc: 0.9603\n",
            "Epoch 85/100\n",
            "274/274 [==============================] - 4s 13ms/step - loss: 0.0441 - accuracy: 0.9203 - auc: 0.9659 - val_loss: 0.2155 - val_accuracy: 0.9188 - val_auc: 0.9604\n",
            "Epoch 86/100\n",
            "274/274 [==============================] - 3s 11ms/step - loss: 0.0440 - accuracy: 0.9209 - auc: 0.9660 - val_loss: 0.2268 - val_accuracy: 0.9149 - val_auc: 0.9605\n",
            "Epoch 87/100\n",
            "274/274 [==============================] - 4s 13ms/step - loss: 0.0443 - accuracy: 0.9205 - auc: 0.9657 - val_loss: 0.2711 - val_accuracy: 0.9047 - val_auc: 0.9600\n",
            "Epoch 88/100\n",
            "274/274 [==============================] - 4s 13ms/step - loss: 0.0436 - accuracy: 0.9217 - auc: 0.9662 - val_loss: 0.2340 - val_accuracy: 0.9088 - val_auc: 0.9607\n",
            "Epoch 89/100\n",
            "274/274 [==============================] - 4s 13ms/step - loss: 0.0443 - accuracy: 0.9197 - auc: 0.9666 - val_loss: 0.2364 - val_accuracy: 0.9089 - val_auc: 0.9605\n",
            "Epoch 90/100\n",
            "274/274 [==============================] - 4s 13ms/step - loss: 0.0435 - accuracy: 0.9219 - auc: 0.9665 - val_loss: 0.2439 - val_accuracy: 0.9112 - val_auc: 0.9609\n",
            "Epoch 91/100\n",
            "274/274 [==============================] - 4s 13ms/step - loss: 0.0438 - accuracy: 0.9212 - auc: 0.9667 - val_loss: 0.1816 - val_accuracy: 0.9290 - val_auc: 0.9604\n",
            "Epoch 92/100\n",
            "274/274 [==============================] - 3s 12ms/step - loss: 0.0438 - accuracy: 0.9211 - auc: 0.9668 - val_loss: 0.2152 - val_accuracy: 0.9174 - val_auc: 0.9606\n",
            "Epoch 93/100\n",
            "274/274 [==============================] - 3s 12ms/step - loss: 0.0437 - accuracy: 0.9212 - auc: 0.9671 - val_loss: 0.2132 - val_accuracy: 0.9211 - val_auc: 0.9608\n",
            "Epoch 94/100\n",
            "274/274 [==============================] - 4s 13ms/step - loss: 0.0438 - accuracy: 0.9216 - auc: 0.9667 - val_loss: 0.1951 - val_accuracy: 0.9272 - val_auc: 0.9602\n",
            "Epoch 95/100\n",
            "274/274 [==============================] - 3s 12ms/step - loss: 0.0433 - accuracy: 0.9230 - auc: 0.9670 - val_loss: 0.2296 - val_accuracy: 0.9156 - val_auc: 0.9604\n",
            "Epoch 96/100\n",
            "274/274 [==============================] - 4s 14ms/step - loss: 0.0436 - accuracy: 0.9214 - auc: 0.9673 - val_loss: 0.2165 - val_accuracy: 0.9204 - val_auc: 0.9607\n",
            "Epoch 97/100\n",
            "274/274 [==============================] - 4s 15ms/step - loss: 0.0436 - accuracy: 0.9219 - auc: 0.9670 - val_loss: 0.1984 - val_accuracy: 0.9271 - val_auc: 0.9610\n",
            "Epoch 98/100\n",
            "274/274 [==============================] - 3s 11ms/step - loss: 0.0431 - accuracy: 0.9230 - auc: 0.9672 - val_loss: 0.2223 - val_accuracy: 0.9150 - val_auc: 0.9610\n",
            "Epoch 99/100\n",
            "274/274 [==============================] - 4s 13ms/step - loss: 0.0430 - accuracy: 0.9231 - auc: 0.9674 - val_loss: 0.2200 - val_accuracy: 0.9169 - val_auc: 0.9610\n",
            "Epoch 100/100\n",
            "274/274 [==============================] - 4s 13ms/step - loss: 0.0433 - accuracy: 0.9229 - auc: 0.9673 - val_loss: 0.1987 - val_accuracy: 0.9247 - val_auc: 0.9608\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f3c9dc3d190>"
            ]
          },
          "metadata": {},
          "execution_count": 229
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kcILeYZI9pxm"
      },
      "source": [
        "<Pre><font size=6>Part-6: Creating a Data pipeline for BERT Model</font> \n",
        "1. Pipeline is a way to codify and automate the workflow.\n",
        "2. Download the test.csv file from here <a href=\"https://drive.google.com/file/d/1QwjqTsqTX2vdy7fTmeXjxP3dq8IAVLpo/view?usp=sharing\">here</a> </pre>\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_74n3sgFjvlM"
      },
      "source": [
        "#there is an alterante way to load files from Google drive directly to your Colab session\n",
        "# you can use gdown module to import the files as follows\n",
        "#for example for test.csv you can write your code as !gdown --id file_id (remove the # from next line and run it)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kwv_BIV9xWt7"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lQcoHbUKjgvF"
      },
      "source": [
        "#read the csv file\n",
        "test_df= pd.read_csv('test.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "-z7j8YmvbLoY",
        "outputId": "7fbfe321-85ca-4eab-fbdf-92f21d7b13cf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                Text\n",
              "0  Just opened Greenies Joint Care (individually ...\n",
              "1  This product rocks :) My mom was very happy w/...\n",
              "2  The product was fine, but the cost of shipping...\n",
              "3  I love this soup. It's great as part of a meal...\n",
              "4  Getting ready to order again. These are great ..."
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-a0f8f50b-e8d3-45bd-85f7-ce4e1acfbb53\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Just opened Greenies Joint Care (individually ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>This product rocks :) My mom was very happy w/...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>The product was fine, but the cost of shipping...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>I love this soup. It's great as part of a meal...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Getting ready to order again. These are great ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a0f8f50b-e8d3-45bd-85f7-ce4e1acfbb53')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-a0f8f50b-e8d3-45bd-85f7-ce4e1acfbb53 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-a0f8f50b-e8d3-45bd-85f7-ce4e1acfbb53');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 238
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-zii6hgejdhQ"
      },
      "source": [
        "<Pre>1. You have to write a function that takes the test_df,trained model and the required parameters as input. \n",
        "2. Perform all the preproceesing steps inside the function.\n",
        "- Remove all the html tags\n",
        "- Now do tokenization [Part 3 as mentioned above]\n",
        "- Create tokens,mask array and segment array\n",
        "- Get Embeddings from BERT Model [Part 4 as mentioned above] , let it be X_test\n",
        "- Print the shape of output(X_test.shape).You should get (352,768)\n",
        "3. Predit the output of X_test with the neural network model which we trained earlier.\n",
        "\n",
        "4. Return the occurences of class labels from the function.\n",
        "The output should be the count of datapoints classified as 1 or 0.\n",
        "\n",
        "</pre>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def bert(X):\n",
        "  X.map(lambda x: re.sub(r'<.*?>', '', x))\n",
        "  tokens = X.map(tokenizer.tokenize)\n",
        "  tokens = tf.keras.preprocessing.sequence.pad_sequences(tokens, max_seq_length - 2,value='[PAD]', dtype=object)\n",
        "  tokens = tokenize_sequence(tokens)\n",
        "\n",
        "  mask = (tokens != '[PAD]')\n",
        "  segment = np.zeros(tokens.shape)\n",
        "  tokens = convert_tokens_to_ids(tokens)\n",
        "  return bert_model.predict([tokens, mask, tokens])\n",
        "def tokenize_sequence(text):\n",
        "  seq = []\n",
        "  for row in text:\n",
        "    seq.append(['[CLS]', *row, '[SEP]'])\n",
        "  return np.array(seq)\n",
        "def convert_tokens_to_ids(text):\n",
        "  ids = []\n",
        "  for row in text:\n",
        "    ids.append(tokenizer.convert_tokens_to_ids(row))\n",
        "  return np.array(ids)"
      ],
      "metadata": {
        "id": "D2QewgpZSEg-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def pipeline(X,m):\n",
        "  return m.predict(bert(X))"
      ],
      "metadata": {
        "id": "AKDgqbeu0Dii"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pred = pipeline(test_df['Text'],model)"
      ],
      "metadata": {
        "id": "EOKTGrMaep6w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pred = pd.DataFrame(pred)"
      ],
      "metadata": {
        "id": "1lw7udwOiT4b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bert(test_df['Text']).shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C642Q12raFo9",
        "outputId": "e90959c7-6358-481e-e84c-9800faf59c70"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(352, 768)"
            ]
          },
          "metadata": {},
          "execution_count": 254
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "result = [1 if x > 0.5 else 0 for x in pred[1]]"
      ],
      "metadata": {
        "id": "bti7eimyiEOd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c7b4-P3wo4j-",
        "outputId": "a77ee135-a9ca-4f76-b27b-90887ec9a25f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pZc7XTQOxcIO"
      },
      "source": [
        "##Steps\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "1.   First i loaded the data and took \"text\" and \"score\" column.\n",
        "2.   Removed review text which had score=3 and remove review if text length is <50.\n",
        "3.   Create a bert model, create tokens,masks,segmants.\n",
        "4.   Train Bert model and get embeddings from the bert.\n",
        "5.   Create a neural network and train it with the embeddings from bert for classification.\n",
        "6.    After training nn for classification create a bert pipeline which does all the above steps for a given input.\n",
        "\n"
      ],
      "metadata": {
        "id": "K-g2EOYwUpIc"
      }
    }
  ]
}